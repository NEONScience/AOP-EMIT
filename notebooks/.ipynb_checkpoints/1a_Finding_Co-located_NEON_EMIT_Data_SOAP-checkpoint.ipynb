{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Finding Co-located EMIT and NEON AOP Data\n",
    "\n",
    "**Summary**  \n",
    "\n",
    "The Earth surface Mineral dust source InvesTigation (EMIT) instrument is located on the International Space Station (ISS) and has collected data over a large area of the Continental US. The National Ecological Observatory Network (NEON) Airborne Observation Platform (AOP) collects aerial remote sensing data, including hyperspectral reflectance data over sites across the United States and Puerto Rico. In this notebook we will show how to utilize the [`earthaccess` Python library](https://github.com/nsidc/earthaccess) to find spatially overlapping EMIT and NEON reflectance data at NEON's [Soaproot Saddle](https://www.neonscience.org/field-sites/soap) site (SOAP) in California. In Sept 2020 and June 2021, the Creek Fire and Blue Fires burned portions of the site, so data at this site would be interesting to investigate wildfire disturbance and recovery.\n",
    "\n",
    "**Background**\n",
    "\n",
    "The **EMIT** instrument is an imaging spectrometer that measures light in visible (V) to short-wave (SWIR) infrared wavelengths; this is also referred to as a VSWIR sensor. These measurements display unique spectral signatures that correspond to the composition on the Earth's surface. The EMIT mission focuses specifically on mapping the composition of minerals to better understand the effects of mineral dust throughout the Earth system and human populations now and in the future. In addition, the EMIT instrument can be used in other applications, such as mapping of greenhouse gases, snow properties, and water resources.\n",
    "\n",
    "More details about EMIT and its associated products can be found on the [EMIT website](https://earth.jpl.nasa.gov/emit/) and [EMIT product pages](https://lpdaac.usgs.gov/product_search/?query=EMIT&status=Operational&view=cards&sort=title) hosted by the LP DAAC.\n",
    "\n",
    "The **NEON Imaging Spectrometer (NIS)** is an airborne [imaging spectrometer](https://www.neonscience.org/data-collection/imaging-spectrometer) built by JPL (AVIRIS-NG) and operated by the National Ecological Observatory Network's (NEON) Airborne Observation Platform (AOP). NEON's hyperspectral sensors collect measurements of sunlight reflected from the Earth's surface in 426 narrow (~5 nm) spectral channels spanning wavelengths between ~ 380 - 2500 nm. NEON's remote sensing data is intended to map and answer questions about a landscape, with ecological applications including identifying and classifying plant species and communities, mapping vegetation health, detecting disease or invasive species, and mapping droughts, wildfires, or other natural disturbances and their impacts. \n",
    "\n",
    "NEON surveys sites spanning the continental US, during peak phenological greenness, capturing each site 3 out of every 5 years, for most terrestrial sites. AOP's [Flight Schedules and Coverage](https://www.neonscience.org/data-collection/flight-schedules-coverage) provide's more information about the current and past schedules.\n",
    "\n",
    "More detailed information about NEON's airborne sampling design can be found in the paper: [Spanning scales: The airborne spatial and temporal sampling design of the National Ecological Observatory Network](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13942).\n",
    "\n",
    "**Requirements**  \n",
    " - [NASA Earthdata Account](https://urs.earthdata.nasa.gov/home)   \n",
    " - *No Python setup requirements if connected to the workshop cloud instance!*  \n",
    " - **Local Only** Set up Python Environment - See **setup_instructions.md** in the `/setup/` folder to set up a local compatible Python environment\n",
    "\n",
    " - NEON API Token (optional, but recommended), see [NEON API Tokens Tutorial](https://www.neonscience.org/resources/learning-hub/tutorials/neon-api-tokens-tutorial)\n",
    "\n",
    "**Download the NEON Flight Boundary Shapefile:** <a href=\"https://www.neonscience.org/sites/default/files/AOP_flightBoxes_0.zip\" class=\"link--button link--arrow\">AOP_flightBoxes.zip</a>\n",
    "\n",
    "**Learning Objectives**  \n",
    "- Use functions provided in an external Python module to find and download available NEON airborne reflectance data.\n",
    "- Use `earthaccess` to find EMIT data that overlaps with a NEON site.\n",
    "- How to export a list of files and download them programmatically.  \n",
    "\n",
    "**Tutorial Outline**  \n",
    "\n",
    "1. Setup\n",
    "2. Explore NEON sites and finding available NEON reflectance data\n",
    "3. Search for EMIT reflectance data  \n",
    "4. Organize and filter results\n",
    "5. Visualize intersecting NEON-EMIT coverage\n",
    "6. Create a list of EMIT asset URLs\n",
    "7. Download EMIT data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Import the required Python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os, sys\n",
    "import folium\n",
    "import earthaccess\n",
    "import warnings\n",
    "import folium.plugins\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import requests\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from branca.element import Figure\n",
    "from IPython.display import display\n",
    "from shapely import geometry\n",
    "from skimage import io\n",
    "from datetime import timedelta\n",
    "from shapely.geometry.polygon import orient\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 NEON Data API and Python Functions\n",
    "\n",
    "Note: In Sept-Oct 2024, these next two chunks of code can be replaced with the Python neonUtilities package, which has built in functions for downloading NEON AOP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download data stored on the internet in a public url to a local file\n",
    "def download_url(url,download_dir):\n",
    "    if not os.path.isdir(download_dir):\n",
    "        os.makedirs(download_dir)\n",
    "    filename = url.split('/')[-1]\n",
    "    r = requests.get(url, allow_redirects=True)\n",
    "    file_object = open(os.path.join(download_dir,filename),'wb')\n",
    "    file_object.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neon_code_folder = './neon_python_modules'\n",
    "aop_download_module_url = \"https://raw.githubusercontent.com/NEONScience/NEON-Data-Skills/main/tutorials/Python/AOP/aop_python_modules/neon_aop_download_functions.py\"\n",
    "download_url(aop_download_module_url,neon_code_folder)\n",
    "#os.listdir(neon_code_folder) #optionally show the contents of this directory to confirm the files downloaded\n",
    "\n",
    "# add the code folder to the path and import the neon aop download functions module\n",
    "sys.path.insert(0,neon_code_folder)\n",
    "import neon_aop_download_functions as aop_dl;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 NASA Earthdata Login Credentials\n",
    "\n",
    "To download or stream NASA data you will need an Earthdata account, you can create one [here](https://urs.earthdata.nasa.gov/home). We will use the `login` function from the `earthaccess` library for authentication before downloading at the end of the notebook. This function can also be used to create a local `.netrc` file if it doesn't exist or add your login info to an existing `.netrc` file. If no Earthdata Login credentials are found in the `.netrc` you'll be prompted for them. This step is not necessary to conduct searches but is needed to download or stream data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search for NEON and EMIT Data\n",
    "\n",
    "NEON data products are hosted on the NEON Data Portal, and can be accessed via an API. We will import a Python module including some functions that interact with the NEON data API to easily see what data are available (in what years), and download data.\n",
    "\n",
    "The EMIT products are hosted by the Land Processes Distributed Active Archive Center (LP DAAC). In this example we will use the cloud-hosted EMIT_L2A_RFL and ECOSTRESS_L2T_LSTE products available from the LP DAAC to find data. Any results we find for these products, should be available for other products within the EMIT and ECOSTRESS collections. \n",
    "\n",
    "To find data we will use the [`earthaccess` Python library](https://github.com/nsidc/earthaccess). `earthaccess` searches NASA's Common Metadata Repository (CMR), a metadata system that catalogs Earth Science data and associated metadata records. The results can then be used to download granules or generate lists of granule search result URLs.\n",
    "\n",
    "Using `earthaccess` we can search based on the attributes of a granule, which can be thought of as a spatiotemporal scene from an instrument containing multiple assets (ex: Reflectance, Reflectance Uncertainty, Masks for the EMIT L2A Reflectance Collection). We can search using attributes such as collection, acquisition time, and spatial footprint. This process can also be used with other EMIT or ECOSTRESS products, other collections, or different data providers, as well as across multiple catalogs with some modification. \n",
    "\n",
    "### 2.1 Define Spatial Regions of Interest (ROIs)\n",
    "\n",
    "For this example, our spatial region of interest (ROI) will be the NEON site [SOAP)](https://www.neonscience.org/field-sites/soap) in the Sierra National Forest, California.\n",
    "\n",
    "In this example, we will create a rectangular ROI surrounding the SOAP flight box. We will search for co-located EMIT data using a polygon rather than a standard bounding box in `earthaccess`. To search for intersections with a polygon using earthaccess, we need to format our ROI as a counterclockwise list of coordinate pairs. \n",
    "\n",
    "Download, Unzip, and Open the shape file (.shp) containing the AOP flight box boundaries, which can be downloaded from [NEON Spatial Data and Maps](https://www.neonscience.org/data-samples/data/spatial-data-maps). Read this into a `geodataframe`, explore the contents, and check the coordinate reference system (CRS) of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and Unzip the NEON Flight Boundary Shapefile\n",
    "neon_boundary_url = \"https://www.neonscience.org/sites/default/files/AOP_flightBoxes_0.zip\"\n",
    "# Use download_url function to save the file to a directory\n",
    "os.makedirs('./data', exist_ok=True)\n",
    "download_url(neon_boundary_url,'./data')\n",
    "# Unzip the file\n",
    "with ZipFile(f\"./data/{neon_boundary_url.split('/')[-1]}\", 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>domainName</th>\n",
       "      <th>siteName</th>\n",
       "      <th>siteID</th>\n",
       "      <th>siteType</th>\n",
       "      <th>sampleType</th>\n",
       "      <th>priority</th>\n",
       "      <th>version</th>\n",
       "      <th>flightbxID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D01</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Bartlett Experimental Forest NEON</td>\n",
       "      <td>BART</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D01_BART_R1_P1_v1</td>\n",
       "      <td>POLYGON ((-71.33426 43.99197, -71.33423 44.081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D01</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Harvard Forest &amp; Quabbin Watershed NEON</td>\n",
       "      <td>HARV</td>\n",
       "      <td>Core</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D01_HARV_C1_P1_v1</td>\n",
       "      <td>POLYGON ((-72.14819 42.5751, -72.14776 42.3837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D01</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Harvard Forest &amp; Quabbin Watershed NEON</td>\n",
       "      <td>HARV</td>\n",
       "      <td>Core</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>D01_HARV_C1_P3_v1</td>\n",
       "      <td>POLYGON ((-72.10812 42.43653, -72.14788 42.436...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D01</td>\n",
       "      <td>Northeast</td>\n",
       "      <td>Lower Hop Brook NEON</td>\n",
       "      <td>HOPB</td>\n",
       "      <td>Core</td>\n",
       "      <td>Aquatic</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D01_HOPB_C1_P2_v1</td>\n",
       "      <td>POLYGON ((-72.36635 42.46399, -72.36635 42.514...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D19</td>\n",
       "      <td>Taiga</td>\n",
       "      <td>Healy NEON</td>\n",
       "      <td>HEAL</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D19_HEAL_R3_P1_v1</td>\n",
       "      <td>POLYGON ((-149.31505 63.82981, -149.31505 63.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  domain domainName                                 siteName siteID  siteType  \\\n",
       "0    D01  Northeast        Bartlett Experimental Forest NEON   BART  Gradient   \n",
       "1    D01  Northeast  Harvard Forest & Quabbin Watershed NEON   HARV      Core   \n",
       "2    D01  Northeast  Harvard Forest & Quabbin Watershed NEON   HARV      Core   \n",
       "3    D01  Northeast                     Lower Hop Brook NEON   HOPB      Core   \n",
       "4    D19      Taiga                               Healy NEON   HEAL  Gradient   \n",
       "\n",
       "    sampleType  priority  version         flightbxID  \\\n",
       "0  Terrestrial         1        1  D01_BART_R1_P1_v1   \n",
       "1  Terrestrial         1        1  D01_HARV_C1_P1_v1   \n",
       "2  Terrestrial         3        1  D01_HARV_C1_P3_v1   \n",
       "3      Aquatic         2        1  D01_HOPB_C1_P2_v1   \n",
       "4  Terrestrial         1        1  D19_HEAL_R3_P1_v1   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-71.33426 43.99197, -71.33423 44.081...  \n",
       "1  POLYGON ((-72.14819 42.5751, -72.14776 42.3837...  \n",
       "2  POLYGON ((-72.10812 42.43653, -72.14788 42.436...  \n",
       "3  POLYGON ((-72.36635 42.46399, -72.36635 42.514...  \n",
       "4  POLYGON ((-149.31505 63.82981, -149.31505 63.9...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aop_flightboxes = gpd.read_file(\"./data/AOP_flightBoxes/AOP_flightboxesAllSites.shp\")\n",
    "aop_flightboxes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World.\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aop_flightboxes.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CRS is **EPSG:4326** (WGS84), which is also the CRS we want the data in to submit for our search of EMIT data.\n",
    "\n",
    "Next, let's examine the AOP flightboxes polygons further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>domainName</th>\n",
       "      <th>siteName</th>\n",
       "      <th>siteID</th>\n",
       "      <th>siteType</th>\n",
       "      <th>sampleType</th>\n",
       "      <th>priority</th>\n",
       "      <th>version</th>\n",
       "      <th>flightbxID</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>D17</td>\n",
       "      <td>Pacific Southwest</td>\n",
       "      <td>Soaproot Saddle NEON</td>\n",
       "      <td>SOAP</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>D17_SOAP_R1_P1_v6</td>\n",
       "      <td>POLYGON ((-119.29195 37.0143, -119.29192 37.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>D17</td>\n",
       "      <td>Pacific Southwest</td>\n",
       "      <td>Soaproot Saddle NEON</td>\n",
       "      <td>SOAP</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D17_SOAP_R1_P2_v2</td>\n",
       "      <td>POLYGON ((-119.32506 37.01417, -119.32506 37.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>D17</td>\n",
       "      <td>Pacific Southwest</td>\n",
       "      <td>Soaproot Saddle NEON</td>\n",
       "      <td>SOAP</td>\n",
       "      <td>Gradient</td>\n",
       "      <td>Terrestrial</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>D17_SOAP_R1_P3_v1</td>\n",
       "      <td>POLYGON ((-119.31839 36.98832, -119.31839 37.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   domain         domainName              siteName siteID  siteType  \\\n",
       "89    D17  Pacific Southwest  Soaproot Saddle NEON   SOAP  Gradient   \n",
       "90    D17  Pacific Southwest  Soaproot Saddle NEON   SOAP  Gradient   \n",
       "91    D17  Pacific Southwest  Soaproot Saddle NEON   SOAP  Gradient   \n",
       "\n",
       "     sampleType  priority  version         flightbxID  \\\n",
       "89  Terrestrial         1        6  D17_SOAP_R1_P1_v6   \n",
       "90  Terrestrial         2        2  D17_SOAP_R1_P2_v2   \n",
       "91  Terrestrial         3        1  D17_SOAP_R1_P3_v1   \n",
       "\n",
       "                                             geometry  \n",
       "89  POLYGON ((-119.29195 37.0143, -119.29192 37.10...  \n",
       "90  POLYGON ((-119.32506 37.01417, -119.32506 37.0...  \n",
       "91  POLYGON ((-119.31839 36.98832, -119.31839 37.0...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_id = 'SOAP'\n",
    "aop_flightboxes[aop_flightboxes.siteID == site_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the site `geodataframe` consists of a single polygon, that we want to include in our study site (sometimes NEON sites may have more than one polygon, as there are sometimes multiple areas, with different priorities for collection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write this to a new variable called \"site_polygon\"\n",
    "site_polygon = aop_flightboxes[aop_flightboxes.siteID == site_id]\n",
    "# subset to only include columns of interest\n",
    "site_polygon = site_polygon[['domain','siteName','siteID','sampleType','flightbxID','priority','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stem2\\AppData\\Local\\Temp\\ipykernel_8632\\2142134814.py:2: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  site_roi_poly = site_polygon.unary_union.envelope\n"
     ]
    }
   ],
   "source": [
    "# Create external boundary of the shape\n",
    "site_roi_poly = site_polygon.unary_union.envelope\n",
    "# Re-order vertices to counterclockwise\n",
    "site_roi_poly = orient(site_roi_poly, sign=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POLYGON ((0 0, 0 3, 3 3, 3 0, 0 0))\n",
      "<shapely.coords.CoordinateSequence object at 0x000001AEF653E6E0>\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Polygon\n",
    "\n",
    "# Sample site_polygon (replace with your actual data)\n",
    "# Assuming site_polygon is a GeoSeries or a list/array of Shapely geometries\n",
    "# For demonstration, let's create a simple MultiPolygon\n",
    "polygon1 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\n",
    "polygon2 = Polygon([(2, 2), (3, 2), (3, 3), (2, 3)])\n",
    "site_polygon = [polygon1, polygon2] #  Use a list of Polygons\n",
    "\n",
    "# Create external boundary of the shape\n",
    "#  The key is to apply envelope to the result of the union\n",
    "from shapely.ops import unary_union\n",
    "site_roi_poly = unary_union(site_polygon).envelope\n",
    "\n",
    "# Re-order vertices to counterclockwise (Shapely doesn't have a built-in direct method for this, but you can find or implement one if needed)\n",
    "#  This part might require more complex logic depending on your needs.\n",
    "#  If you need a counter-clockwise order, you might have to implement a function.\n",
    "#  For simple cases where the envelope is a rectangle, you can reorder the points manually if needed.\n",
    "#  Shapely returns the points of the envelope in a specific order, not necessarily always counterclockwise.\n",
    "#  If the envelope is a simple rectangle, you could do something like this (this is a simplification and might not work for all envelopes):\n",
    "\n",
    "if site_roi_poly.geom_type == 'Polygon':\n",
    "    coords = list(site_roi_poly.exterior.coords)\n",
    "    #  Example reordering (this is VERY simplistic and assumes a rectangular shape)\n",
    "    #  A general solution is more complex and involves calculating angles.\n",
    "    site_roi_poly = Polygon(coords[::-1]) #Reverses the coordinates.  This works for a rectangle, but is not a general solution.\n",
    "\n",
    "print(site_roi_poly)\n",
    "print(site_roi_poly.exterior.coords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a `GeoDataFrame` consisting of the bounding box geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOAP ROI Bounding Box</td>\n",
       "      <td>POLYGON ((0 0, 0 3, 3 3, 3 0, 0 0))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name                             geometry\n",
       "0  SOAP ROI Bounding Box  POLYGON ((0 0, 0 3, 3 3, 3 0, 0 0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_df = pd.DataFrame({\"Name\":[\"SOAP ROI Bounding Box\"]})\n",
    "site_bbox = gpd.GeoDataFrame({\"Name\":[\"SOAP ROI Bounding Box\"], \"geometry\":[site_roi_poly]},crs=\"EPSG:4326\")\n",
    "site_bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write this bounding box to a `geojson` file for use in future notebooks. This is commented out for now, but you can uncomment and run the cell below, if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can visualize our region of interest and the exterior boundary polygon containing ROIs. First add a function to help reformat bounding box coordinates to work with leaflet notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to convert a bounding box for use in leaflet notation\n",
    "def convert_bounds(bbox, invert_y=False):\n",
    "    \"\"\"\n",
    "    Helper method for changing bounding box representation to leaflet notation\n",
    "\n",
    "    ``(lon1, lat1, lon2, lat2) -> ((lat1, lon1), (lat2, lon2))``\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    if invert_y:\n",
    "        y1, y2 = y2, y1\n",
    "    return ((y1, x1), (y2, x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'explore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m folium\u001b[38;5;241m.\u001b[39mGeoJson(site_bbox, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39madd_to(map1)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Add site roi geodataframe\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43msite_polygon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplore\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflightbxID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m                      popup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m                      categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m                      cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m                      style_kwds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, fillOpacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m),\n\u001b[0;32m     14\u001b[0m                      name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSOAP ROI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m                      m\u001b[38;5;241m=\u001b[39mmap1)\n\u001b[0;32m     17\u001b[0m map1\u001b[38;5;241m.\u001b[39madd_child(folium\u001b[38;5;241m.\u001b[39mLayerControl())\n\u001b[0;32m     18\u001b[0m map1\u001b[38;5;241m.\u001b[39mfit_bounds(bounds\u001b[38;5;241m=\u001b[39mconvert_bounds(site_polygon\u001b[38;5;241m.\u001b[39munary_union\u001b[38;5;241m.\u001b[39mbounds))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'explore'"
     ]
    }
   ],
   "source": [
    "fig = Figure(width=\"750px\", height=\"375px\")\n",
    "map1 = folium.Map(tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}', attr='Google')\n",
    "fig.add_child(map1)\n",
    "\n",
    "# Add Site Bounding Box\n",
    "folium.GeoJson(site_bbox, name='bounding_box').add_to(map1)\n",
    "\n",
    "# Add site roi geodataframe\n",
    "site_polygon.explore(\"flightbxID\",\n",
    "                     popup=True,\n",
    "                     categorical=True,\n",
    "                     cmap='Set3',\n",
    "                     style_kwds=dict(opacity=0.7, fillOpacity=0.4),\n",
    "                     name=\"SOAP ROI\",\n",
    "                     m=map1)\n",
    "\n",
    "map1.add_child(folium.LayerControl())\n",
    "map1.fit_bounds(bounds=convert_bounds(site_polygon.unary_union.bounds))\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import geopandas\n",
    "from shapely.geometry import Polygon\n",
    "import sys  # Import sys for error printing\n",
    "\n",
    "\n",
    "def convert_bounds(bounds):\n",
    "    \"\"\"Convert Shapely bounds to Folium bounds (swapped).\"\"\"\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    return [(miny, minx), (maxy, maxx)]\n",
    "\n",
    "\n",
    "def create_map(site_bbox, site_polygon):\n",
    "    \"\"\"\n",
    "    Creates a Folium map with the site bounding box and site ROI.\n",
    "\n",
    "    Args:\n",
    "        site_bbox: GeoJSON-like dictionary representing the bounding box.\n",
    "        site_polygon: GeoDataFrame representing the site ROI.\n",
    "\n",
    "    Returns:\n",
    "        A Folium map object.  Returns None on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fig = folium.Figure(width=\"750px\", height=\"375px\")\n",
    "        map1 = folium.Map(\n",
    "            tiles=\"https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}\",\n",
    "            attr=\"Google\",\n",
    "        )\n",
    "        fig.add_child(map1)\n",
    "\n",
    "        # Add Site Bounding Box\n",
    "        folium.GeoJson(site_bbox, name=\"bounding_box\").add_to(map1)\n",
    "\n",
    "        # Add site roi geodataframe\n",
    "        # Use GeoPandas explore() method, and pass the map\n",
    "        site_polygon.explore(\n",
    "            \"flightbxID\",\n",
    "            popup=True,\n",
    "            categorical=True,\n",
    "            cmap=\"Set3\",\n",
    "            style_kwds=dict(opacity=0.7, fillOpacity=0.4),\n",
    "            name=\"SOAP ROI\",\n",
    "            m=map1,  # Pass the Folium map object\n",
    "        )\n",
    "\n",
    "        map1.add_child(folium.LayerControl())\n",
    "\n",
    "        #  Use unary_union on the GeoSeries, then get the bounds.\n",
    "        # bounds = site_polygon.unary_union.bounds # Deprecated\n",
    "        bounds = site_polygon.geometry.union_all().bounds\n",
    "        map1.fit_bounds(bounds=convert_bounds(bounds))\n",
    "        fig.add_to(map1)  # Add the figure containing the map\n",
    "\n",
    "        return map1  # Return the map object\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating map: {e}\", file=sys.stderr)  # Print to standard error\n",
    "        return None  # Return None to indicate failure\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the map creation and display.\"\"\"\n",
    "    # Sample data (replace with your actual data)\n",
    "    # Assuming site_bbox is a GeoJSON-like dictionary representing the bounding box\n",
    "    site_bbox = {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "            [(-80, 34), (-81, 34), (-81, 35), (-80, 35), (-80, 34)]\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Create a GeoDataFrame for site_polygon\n",
    "    polygon1 = Polygon([(0, 0), (1, 0), (1, 1), (0, 1)])\n",
    "    polygon2 = Polygon([(2, 2), (3, 2), (3, 3), (2, 3)])\n",
    "    site_polygon = geopandas.GeoDataFrame(\n",
    "        {\"geometry\": [polygon1, polygon2], \"flightbxID\": [\"A\", \"B\"]}\n",
    "    )\n",
    "\n",
    "    # Create and display the map\n",
    "    my_map = create_map(site_bbox, site_polygon)\n",
    "    if my_map:  # Only try to display if the map was successfully created.\n",
    "        my_map  # Display the map.  In a notebook, this should render it.\n",
    "    else:\n",
    "        print(\"Map creation failed.\", file=sys.stderr)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the SOAP flightbox, and the exterior boundary polygon containing the full area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need to convert our polygon to a list of coordinate pairs, to create our Region of Interest (ROI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0), (0.0, 3.0), (3.0, 3.0), (3.0, 0.0), (0.0, 0.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set ROI as list of exterior polygon vertices as coordinate pairs\n",
    "site_roi = list(site_roi_poly.exterior.coords)\n",
    "site_roi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can look at the available NEON hyperspectral reflectance data over the site. NEON hyperspectral reflectance data are currently available under two different revisions, as AOP is in the process of implementing a BRDF (Bidirectional Reflectance Distribution Function), but this has not been applied to the full archive of data yet. These data are available under two revisions of the data product ID DP3.30006 - DP3.30006.001 are the directional surface reflectance, and DP3.30006.002 are the bidirectional (BRDF- and topographic- corrected) surface reflectance. Let's see what's available for each of these data products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "refl_rev1_dpid = 'DP3.30006.001'\n",
    "refl_rev2_dpid = 'DP3.30006.002'\n",
    "site = site_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directional Reflectance Data Available at NEON Site SOAP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://data.neonscience.org/api/v0/data/DP3.30006.001/SOAP/2013-06',\n",
       " 'https://data.neonscience.org/api/v0/data/DP3.30006.001/SOAP/2017-07',\n",
       " 'https://data.neonscience.org/api/v0/data/DP3.30006.001/SOAP/2018-06',\n",
       " 'https://data.neonscience.org/api/v0/data/DP3.30006.001/SOAP/2019-06',\n",
       " 'https://data.neonscience.org/api/v0/data/DP3.30006.001/SOAP/2021-07']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Directional Reflectance Data Available at NEON Site {site_id}')\n",
    "aop_dl.list_available_urls(refl_rev1_dpid,site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bidirectional Reflectance Data Available at NEON Site SOAP\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://data.neonscience.org/api/v0/data/DP3.30006.002/SOAP/2023-06',\n",
       " 'https://data.neonscience.org/api/v0/data/DP3.30006.002/SOAP/2023-07',\n",
       " 'https://data.neonscience.org/api/v0/data/DP3.30006.002/SOAP/2024-06']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Bidirectional Reflectance Data Available at NEON Site {site_id}')\n",
    "aop_dl.list_available_urls(refl_rev2_dpid,site)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bidirectional data for the 2nd 2023 and 2024 visits of SOAP may have some overlap with EMIT data. Let's start with 2024 AOP data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = '2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download the reflectance data using the function `aop_dl.download_aop_files`. You can change the download path if desired.\n",
    "\n",
    "Before we download the data, let's look at the spatial extent. AOP data are provided in UTM projection. We can do this by downloading shapefiles of the tile boundaries. These are available as metadata provided along with the reflectance data products. The full boundary of the site is a file called \"merged_tiles.shp/.shx\". Let's only download this shapefile so we can see the file extent, and determine the UTM coordinates of the tiles we wish to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aop_dl.download_aop_files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the full-boundary shape files from the lidar data. These are delivered as metadata as part of one of the Lidar data products, so note that the data product id (DPID) is different\n",
    "# aop_dl.download_aop_files('DP1.30003.001',site,year,'./data/neon_refl',match_string='.shp',check_size=False)\n",
    "# aop_dl.download_aop_files('DP1.30003.001',site,year,'./data/neon_refl',match_string='.shx',check_size=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reflectance data can be large in size, so for now, we'll just download a single tile, in the center of the site. We can do that with the `download_aop_files` function as follows. This time leave out the `check_size` input parameter, and that will default to True. This will prompt you to download after displaying the download size. This reflectance file is ~615 MB, so make sure you have enough space on your local disk before downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download a reflectance hdf5 tile\n",
    "# aop_dl.download_aop_files('DP3.30006.002',site,year,'./data/neon_refl',match_string='568000_4901000_reflectance.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define EMIT Collections of Interest\n",
    "We need to specify which products we want to search for. The best way to do this is using their concept-id. As mentioned above, we will conduct our search using the EMIT Level 2A Reflectance (EMITL2ARFL). We can do some quick collection queries using `earthaccess` to retrieve the concept-id for each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\n",
       "   \"meta\": {\n",
       "     \"concept-id\": \"C2408750690-LPCLOUD\",\n",
       "     \"granule-count\": 150425,\n",
       "     \"provider-id\": \"LPCLOUD\"\n",
       "   },\n",
       "   \"umm\": {\n",
       "     \"ShortName\": \"EMITL2ARFL\",\n",
       "     \"EntryTitle\": \"EMIT L2A Estimated Surface Reflectance and Uncertainty and Masks 60 m V001\",\n",
       "     \"Version\": \"001\"\n",
       "   }\n",
       " }]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EMIT Collection Query\n",
    "emit_collection_query = earthaccess.collection_query().keyword('EMIT L2A Reflectance')\n",
    "emit_collection_query.fields(['ShortName','EntryTitle','Version']).get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your search returns multiple products, be sure to select the right concept-id For this example it will be the first one. Create a list of these concept-ids for our data search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Collections for our search\n",
    "emit_concept_id = ['C2408750690-LPCLOUD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define Date Range\n",
    "\n",
    "For our date range, we'll look at data collected between January 2022 and October 2023. The `date_range` can be specified as a pair of dates, start and end (up to, not including)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Date Range\n",
    "date_range = ('2022-01-01','2024-11-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Searching\n",
    "\n",
    "Submit a query using `earthaccess`, usin the `site_roi` as the region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "{\"errors\":[\"The polygon boundary points are listed in the wrong order. Points must be provided in counter-clockwise order.\"]}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\lpdaac_vitals\\lib\\site-packages\\earthaccess\\search.py:441\u001b[0m, in \u001b[0;36mDataGranules.hits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lpdaac_vitals\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://cmr.earthdata.nasa.gov/search/granules.umm_json?concept_id%5B%5D=C2408750690-LPCLOUD&polygon=0.0,0.0,0.0,3.0,3.0,3.0,3.0,0.0,0.0,0.0&temporal%5B%5D=2022-01-01T00:00:00Z,2024-11-01T23:59:59Z&page_size=0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m emit_query_results \u001b[38;5;241m=\u001b[39m \u001b[43mearthaccess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcept_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43memit_concept_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolygon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msite_roi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemporal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lpdaac_vitals\\lib\\site-packages\\earthaccess\\api.py:128\u001b[0m, in \u001b[0;36msearch_data\u001b[1;34m(count, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     query \u001b[38;5;241m=\u001b[39m DataGranules()\u001b[38;5;241m.\u001b[39mparameters(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 128\u001b[0m granules_found \u001b[38;5;241m=\u001b[39m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhits\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGranules found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgranules_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lpdaac_vitals\\lib\\site-packages\\earthaccess\\search.py:444\u001b[0m, in \u001b[0;36mDataGranules.hits\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ex\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(ex\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(ex)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mex\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: {\"errors\":[\"The polygon boundary points are listed in the wrong order. Points must be provided in counter-clockwise order.\"]}"
     ]
    }
   ],
   "source": [
    "emit_query_results = earthaccess.search_data(\n",
    "    concept_id=emit_concept_id,\n",
    "    polygon=site_roi,\n",
    "    temporal=date_range,\n",
    "    count=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 results.\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': -0.5144497156143188, 'Latitude': 0.9309459328651428}, {'Longitude': -1.1108078956604004, 'Latitude': 0.5103387236595154}, {'Longitude': -0.335060715675354, 'Latitude': -0.5895549654960632}, {'Longitude': 0.26129746437072754, 'Latitude': -0.1689477562904358}, {'Longitude': -0.5144497156143188, 'Latitude': 0.9309459328651428}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2023-04-29T11:32:04Z', 'EndingDateTime': '2023-04-29T11:32:24Z'}}\n",
      "Size(MB): 6085.387665748596\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230429T113204_2311907_026/EMIT_L2A_RFL_001_20230429T113204_2311907_026.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230429T113204_2311907_026/EMIT_L2A_RFLUNCERT_001_20230429T113204_2311907_026.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20230429T113204_2311907_026/EMIT_L2A_MASK_001_20230429T113204_2311907_026.nc']\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': -0.19050008058547974, 'Latitude': 0.8117561340332031}, {'Longitude': -0.7861952185630798, 'Latitude': 0.3923960030078888}, {'Longitude': -0.011136949062347412, 'Latitude': -0.7085633277893066}, {'Longitude': 0.5845581889152527, 'Latitude': -0.2892031967639923}, {'Longitude': -0.19050008058547974, 'Latitude': 0.8117561340332031}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2023-10-29T11:03:54Z', 'EndingDateTime': '2023-10-29T11:04:14Z'}}\n",
      "Size(MB): 6085.0990171432495\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20231029T110354_2330207_024/EMIT_L2A_RFLUNCERT_001_20231029T110354_2330207_024.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20231029T110354_2330207_024/EMIT_L2A_RFL_001_20231029T110354_2330207_024.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20231029T110354_2330207_024/EMIT_L2A_MASK_001_20231029T110354_2330207_024.nc']\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': 0.20665140450000763, 'Latitude': 0.2456982433795929}, {'Longitude': -0.3914934992790222, 'Latitude': -0.17548775672912598}, {'Longitude': 0.08579342067241669, 'Latitude': -0.8533039093017578}, {'Longitude': 0.6839383244514465, 'Latitude': -0.43211793899536133}, {'Longitude': 0.20665140450000763, 'Latitude': 0.2456982433795929}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2023-12-29T10:55:01Z', 'EndingDateTime': '2023-12-29T10:55:13Z'}}\n",
      "Size(MB): 3579.3963537216187\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20231229T105501_2336307_006/EMIT_L2A_RFL_001_20231229T105501_2336307_006.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20231229T105501_2336307_006/EMIT_L2A_RFLUNCERT_001_20231229T105501_2336307_006.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20231229T105501_2336307_006/EMIT_L2A_MASK_001_20231229T105501_2336307_006.nc']\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': -0.43677666783332825, 'Latitude': 0.9663369655609131}, {'Longitude': -1.04362154006958, 'Latitude': 0.5387195944786072}, {'Longitude': -0.5662603378295898, 'Latitude': -0.1387183666229248}, {'Longitude': 0.040584564208984375, 'Latitude': 0.2888990044593811}, {'Longitude': -0.43677666783332825, 'Latitude': 0.9663369655609131}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2024-06-28T10:50:37Z', 'EndingDateTime': '2024-06-28T10:50:49Z'}}\n",
      "Size(MB): 3577.569682121277\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240628T105037_2418007_007/EMIT_L2A_RFL_001_20240628T105037_2418007_007.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240628T105037_2418007_007/EMIT_L2A_RFLUNCERT_001_20240628T105037_2418007_007.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240628T105037_2418007_007/EMIT_L2A_MASK_001_20240628T105037_2418007_007.nc']\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': 0.4481472969055176, 'Latitude': 0.3523563742637634}, {'Longitude': -0.15858863294124603, 'Latitude': -0.07510894536972046}, {'Longitude': 0.3197600841522217, 'Latitude': -0.7540677785873413}, {'Longitude': 0.9264960289001465, 'Latitude': -0.3266024589538574}, {'Longitude': 0.4481472969055176, 'Latitude': 0.3523563742637634}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2024-07-02T09:15:32Z', 'EndingDateTime': '2024-07-02T09:15:44Z'}}\n",
      "Size(MB): 3577.1219968795776\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240702T091532_2418406_008/EMIT_L2A_RFL_001_20240702T091532_2418406_008.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240702T091532_2418406_008/EMIT_L2A_MASK_001_20240702T091532_2418406_008.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240702T091532_2418406_008/EMIT_L2A_RFLUNCERT_001_20240702T091532_2418406_008.nc']\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': -0.46665170788764954, 'Latitude': 0.7486660480499268}, {'Longitude': -1.070448637008667, 'Latitude': 0.3234563171863556}, {'Longitude': -0.29519936442375183, 'Latitude': -0.7773962616920471}, {'Longitude': 0.3085975646972656, 'Latitude': -0.35218653082847595}, {'Longitude': -0.46665170788764954, 'Latitude': 0.7486660480499268}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2024-08-28T10:42:14Z', 'EndingDateTime': '2024-08-28T10:42:34Z'}}\n",
      "Size(MB): 6084.706935882568\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240828T104214_2424107_008/EMIT_L2A_RFL_001_20240828T104214_2424107_008.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240828T104214_2424107_008/EMIT_L2A_RFLUNCERT_001_20240828T104214_2424107_008.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240828T104214_2424107_008/EMIT_L2A_MASK_001_20240828T104214_2424107_008.nc']\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': -0.3738775849342346, 'Latitude': 0.6579586267471313}, {'Longitude': -0.9795021414756775, 'Latitude': 0.23144899308681488}, {'Longitude': -0.5015291571617126, 'Latitude': -0.44725120067596436}, {'Longitude': 0.10409539937973022, 'Latitude': -0.020741567015647888}, {'Longitude': -0.3738775849342346, 'Latitude': 0.6579586267471313}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2024-09-01T09:08:47Z', 'EndingDateTime': '2024-09-01T09:08:59Z'}}\n",
      "Size(MB): 3579.073932647705\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240901T090847_2424506_002/EMIT_L2A_RFL_001_20240901T090847_2424506_002.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240901T090847_2424506_002/EMIT_L2A_RFLUNCERT_001_20240901T090847_2424506_002.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240901T090847_2424506_002/EMIT_L2A_MASK_001_20240901T090847_2424506_002.nc']\n",
      "Collection: {'ShortName': 'EMITL2ARFL', 'Version': '001'}\n",
      "Spatial coverage: {'HorizontalSpatialDomain': {'Geometry': {'GPolygons': [{'Boundary': {'Points': [{'Longitude': 0.05015003681182861, 'Latitude': 0.05565452575683594}, {'Longitude': -0.5554510951042175, 'Latitude': -0.3710376024246216}, {'Longitude': 0.21971142292022705, 'Latitude': -1.4712203741073608}, {'Longitude': 0.8253125548362732, 'Latitude': -1.0445282459259033}, {'Longitude': 0.05015003681182861, 'Latitude': 0.05565452575683594}]}}]}}}\n",
      "Temporal coverage: {'RangeDateTime': {'BeginningDateTime': '2024-09-01T09:08:59Z', 'EndingDateTime': '2024-09-01T09:09:19Z'}}\n",
      "Size(MB): 6085.191296577454\n",
      "Data: ['https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240901T090859_2424506_003/EMIT_L2A_RFL_001_20240901T090859_2424506_003.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240901T090859_2424506_003/EMIT_L2A_RFLUNCERT_001_20240901T090859_2424506_003.nc', 'https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/EMITL2ARFL.001/EMIT_L2A_RFL_001_20240901T090859_2424506_003/EMIT_L2A_MASK_001_20240901T090859_2424506_003.nc']\n"
     ]
    }
   ],
   "source": [
    "import earthaccess\n",
    "from shapely.geometry import Polygon\n",
    "import sys  # Import sys for error printing\n",
    "\n",
    "#  Define the function to ensure the polygon is in counter-clockwise order\n",
    "def ensure_counterclockwise(polygon):\n",
    "    \"\"\"\n",
    "    Ensures that the given Shapely Polygon's exterior ring is oriented counter-clockwise.\n",
    "\n",
    "    Args:\n",
    "        polygon: A Shapely Polygon object.\n",
    "\n",
    "    Returns:\n",
    "        A Shapely Polygon object with a counter-clockwise oriented exterior ring.\n",
    "    \"\"\"\n",
    "    if not polygon.exterior.is_ccw:\n",
    "        coords = list(polygon.exterior.coords)\n",
    "        return Polygon(coords[::-1], holes=[list(interior.coords) for interior in polygon.interiors])\n",
    "    return polygon\n",
    "\n",
    "def polygon_to_coord_list(polygon):\n",
    "    \"\"\"\n",
    "    Converts a Shapely Polygon to a list of coordinate tuples.\n",
    "\n",
    "    Args:\n",
    "        polygon: A Shapely Polygon object\n",
    "\n",
    "    Returns:\n",
    "        A list of coordinate tuples representing the exterior ring of the polygon.\n",
    "        e.g., [(x1, y1), (x2, y2), ..., (xn, yn)]\n",
    "    \"\"\"\n",
    "    return list(polygon.exterior.coords)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the data search.\"\"\"\n",
    "    # Example Ecoregion polygon (replace with your actual polygon)\n",
    "    # Polygon needs to be defined in counter-clockwise order.\n",
    "    # Example polygon (originally clockwise):\n",
    "    # site_roi = [(0.0, 0.0), (0.0, 3.0), (3.0, 3.0), (3.0, 0.0), (0.0, 0.0)]\n",
    "    # Define polygon in counter-clockwise order:\n",
    "    site_roi_coords = [(0.0, 0.0), (3.0, 0.0), (3.0, 3.0), (0.0, 3.0), (0.0, 0.0)]\n",
    "    site_roi_polygon = Polygon(site_roi_coords)\n",
    "\n",
    "    # Ensure the polygon is counter-clockwise\n",
    "    site_roi_polygon = ensure_counterclockwise(site_roi_polygon)\n",
    "\n",
    "    # Convert the Shapely Polygon to a list of coordinates\n",
    "    site_roi_coords_list = polygon_to_coord_list(site_roi_polygon)\n",
    "\n",
    "\n",
    "    emit_concept_id = \"C2408750690-LPCLOUD\"  # Example concept ID\n",
    "    date_range = (\"2022-01-01T00:00:00Z\", \"2024-11-01T23:59:59Z\")\n",
    "\n",
    "    try:\n",
    "        emit_query_results = earthaccess.search_data(\n",
    "            concept_id=emit_concept_id,\n",
    "            polygon=site_roi_coords_list,  # Pass the list of coordinates\n",
    "            temporal=date_range,\n",
    "            count=500,\n",
    "        )\n",
    "        print(f\"Found {len(emit_query_results)} results.\")\n",
    "        # Process the results as needed\n",
    "        for item in emit_query_results:\n",
    "            print(item)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data search: {e}\", file=sys.stderr)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Organizing and Filtering Results\n",
    "\n",
    "As we can see from above, the results object contains a list of objects with metadata and links. We can convert this to a more readable format, a dataframe. In addition, we can make it a geodataframe by taking the spatial metadata and creating a shapely polygon representing the spatial coverage, and further customize which information we want to use from other metadata fields.\n",
    "\n",
    "First, we define some functions to help us create a shapely object for our geodataframe, and retrieve the specific browse image URLs that we want. By default, the browse image selected by `earthaccess` is the first one in the list, but the ECO_L2_LSTE has several browse images, and we want to make sure we retrieve the `png` file, which is a preview of the LSTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create shapely polygon of spatial coverage\n",
    "def get_shapely_object(result:earthaccess.results.DataGranule):\n",
    "    # Get Geometry Keys\n",
    "    geo = result['umm']['SpatialExtent']['HorizontalSpatialDomain']['Geometry']\n",
    "    keys = geo.keys()\n",
    "\n",
    "    if 'BoundingRectangles' in keys:\n",
    "        bounding_rectangle = geo['BoundingRectangles'][0]\n",
    "        # Create bbox tuple\n",
    "        bbox_coords = (bounding_rectangle['WestBoundingCoordinate'],bounding_rectangle['SouthBoundingCoordinate'],\n",
    "                    bounding_rectangle['EastBoundingCoordinate'],bounding_rectangle['NorthBoundingCoordinate'])\n",
    "        # Create shapely geometry from bbox\n",
    "        shape = geometry.box(*bbox_coords, ccw=True)\n",
    "    elif 'GPolygons' in keys:\n",
    "        points = geo['GPolygons'][0]['Boundary']['Points']\n",
    "        # Create shapely geometry from polygons\n",
    "        shape = geometry.Polygon([[p['Longitude'],p['Latitude']] for p in points])\n",
    "    else:\n",
    "         raise ValueError('Provided result does not contain bounding boxes/polygons or is incompatible.')\n",
    "    return(shape)\n",
    "\n",
    "# Retrieve png browse image if it exists or first jpg in list of urls\n",
    "def get_png(result:earthaccess.results.DataGranule):\n",
    "    https_links = [link for link in result.dataviz_links() if 'https' in link]\n",
    "    if len(https_links) == 1:\n",
    "        browse = https_links[0]\n",
    "    elif len(https_links) == 0:\n",
    "        browse = 'no browse image'\n",
    "        warnings.warn(f\"There is no browse imagery for {result['umm']['GranuleUR']}.\")\n",
    "    else:\n",
    "        browse = [png for png in https_links if '.png' in png][0]\n",
    "    return(browse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our functions we can create a dataframe, then calculate and add our shapely geometries to make a geodataframe. After that, add a column for our browse image urls and print the number of granules in our results, so we can monitor the quantity we  are working with a we winnow down to the data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emit_query_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Create Dataframe of Results Metadata\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m emit_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mjson_normalize(\u001b[43memit_query_results\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m emit_results_df\u001b[38;5;241m.\u001b[39mempty:  \u001b[38;5;66;03m# Check if the DataFrame is not empty\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Create shapely polygons for result\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     geometries \u001b[38;5;241m=\u001b[39m [get_shapely_object(emit_query_results[index]) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m emit_results_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mto_list()]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emit_query_results' is not defined"
     ]
    }
   ],
   "source": [
    "# Create Dataframe of Results Metadata\n",
    "emit_results_df = pd.json_normalize(emit_query_results)\n",
    "if not emit_results_df.empty:  # Check if the DataFrame is not empty\n",
    "    # Create shapely polygons for result\n",
    "    geometries = [get_shapely_object(emit_query_results[index]) for index in emit_results_df.index.to_list()]\n",
    "    # Convert to GeoDataframe\n",
    "    emit_gdf = gpd.GeoDataFrame(emit_results_df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    # Add browse imagery links\n",
    "    emit_gdf['browse'] = [get_png(granule) for granule in emit_query_results]\n",
    "    emit_gdf['shortname'] = [result.get('umm', {}).get('CollectionReference', {}).get('ShortName') for result in emit_query_results]\n",
    "    # Preview GeoDataframe\n",
    "    print(f'{emit_gdf.shape[0]} granules total')\n",
    "else:\n",
    "    print(\"emit_results_df is empty. No granules to process.\")\n",
    "    emit_gdf = gpd.GeoDataFrame() # Return an empty GeoDataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally preview the geodataframe to get an idea what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#emit_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of columns with data that is not relevant for this exercise, so we can drop those. To do that, list the names of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List Column Names\n",
    "# emit_gdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a list of columns to keep and use it to filter the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 results.\n",
      "8 granules total\n",
      "          size meta.concept-type      meta.concept-id  meta.revision-id  \\\n",
      "0  6085.387666           granule  G2677797595-LPCLOUD                 2   \n",
      "1  6085.099017           granule  G2794186271-LPCLOUD                 2   \n",
      "2  3579.396354           granule  G2827183842-LPCLOUD                 2   \n",
      "3  3577.569682           granule  G3142899424-LPCLOUD                 2   \n",
      "4  3577.121997           granule  G3149675777-LPCLOUD                 2   \n",
      "\n",
      "                                 meta.native-id meta.collection-concept-id  \\\n",
      "0  EMIT_L2A_RFL_001_20230429T113204_2311907_026        C2408750690-LPCLOUD   \n",
      "1  EMIT_L2A_RFL_001_20231029T110354_2330207_024        C2408750690-LPCLOUD   \n",
      "2  EMIT_L2A_RFL_001_20231229T105501_2336307_006        C2408750690-LPCLOUD   \n",
      "3  EMIT_L2A_RFL_001_20240628T105037_2418007_007        C2408750690-LPCLOUD   \n",
      "4  EMIT_L2A_RFL_001_20240702T091532_2418406_008        C2408750690-LPCLOUD   \n",
      "\n",
      "  meta.provider-id                        meta.format  \\\n",
      "0          LPCLOUD  application/vnd.nasa.cmr.umm+json   \n",
      "1          LPCLOUD  application/vnd.nasa.cmr.umm+json   \n",
      "2          LPCLOUD  application/vnd.nasa.cmr.umm+json   \n",
      "3          LPCLOUD  application/vnd.nasa.cmr.umm+json   \n",
      "4          LPCLOUD  application/vnd.nasa.cmr.umm+json   \n",
      "\n",
      "         meta.revision-date  \\\n",
      "0  2024-10-25T03:57:46.346Z   \n",
      "1  2024-10-25T22:56:04.956Z   \n",
      "2  2024-10-26T02:04:45.313Z   \n",
      "3  2024-10-26T19:20:38.690Z   \n",
      "4  2024-10-28T15:19:12.191Z   \n",
      "\n",
      "  umm.TemporalExtent.RangeDateTime.BeginningDateTime  ...  \\\n",
      "0                               2023-04-29T11:32:04Z  ...   \n",
      "1                               2023-10-29T11:03:54Z  ...   \n",
      "2                               2023-12-29T10:55:01Z  ...   \n",
      "3                               2024-06-28T10:50:37Z  ...   \n",
      "4                               2024-07-02T09:15:32Z  ...   \n",
      "\n",
      "  umm.DataGranule.DayNightFlag  \\\n",
      "0                          Day   \n",
      "1                          Day   \n",
      "2                          Day   \n",
      "3                          Day   \n",
      "4                          Day   \n",
      "\n",
      "   umm.DataGranule.ArchiveAndDistributionInformation  \\\n",
      "0  [{'Name': 'EMIT_L2A_RFL_001_20230429T113204_23...   \n",
      "1  [{'Name': 'EMIT_L2A_RFL_001_20231029T110354_23...   \n",
      "2  [{'Name': 'EMIT_L2A_RFL_001_20231229T105501_23...   \n",
      "3  [{'Name': 'EMIT_L2A_RFL_001_20240628T105037_24...   \n",
      "4  [{'Name': 'EMIT_L2A_RFL_001_20240702T091532_24...   \n",
      "\n",
      "  umm.DataGranule.ProductionDateTime  \\\n",
      "0               2023-05-05T04:29:10Z   \n",
      "1               2023-11-02T11:35:32Z   \n",
      "2               2023-12-30T09:22:04Z   \n",
      "3               2024-07-02T20:23:48Z   \n",
      "4               2024-07-07T08:34:32Z   \n",
      "\n",
      "                                       umm.Platforms  \\\n",
      "0  [{'ShortName': 'ISS', 'Instruments': [{'ShortN...   \n",
      "1  [{'ShortName': 'ISS', 'Instruments': [{'ShortN...   \n",
      "2  [{'ShortName': 'ISS', 'Instruments': [{'ShortN...   \n",
      "3  [{'ShortName': 'ISS', 'Instruments': [{'ShortN...   \n",
      "4  [{'ShortName': 'ISS', 'Instruments': [{'ShortN...   \n",
      "\n",
      "                       umm.MetadataSpecification.URL  \\\n",
      "0  https://cdn.earthdata.nasa.gov/umm/granule/v1.6.6   \n",
      "1  https://cdn.earthdata.nasa.gov/umm/granule/v1.6.6   \n",
      "2  https://cdn.earthdata.nasa.gov/umm/granule/v1.6.6   \n",
      "3  https://cdn.earthdata.nasa.gov/umm/granule/v1.6.6   \n",
      "4  https://cdn.earthdata.nasa.gov/umm/granule/v1.6.6   \n",
      "\n",
      "  umm.MetadataSpecification.Name umm.MetadataSpecification.Version geometry  \\\n",
      "0                          UMM-G                             1.6.6     None   \n",
      "1                          UMM-G                             1.6.6     None   \n",
      "2                          UMM-G                             1.6.6     None   \n",
      "3                          UMM-G                             1.6.6     None   \n",
      "4                          UMM-G                             1.6.6     None   \n",
      "\n",
      "  browse   shortname  \n",
      "0   None  EMITL2ARFL  \n",
      "1   None  EMITL2ARFL  \n",
      "2   None  EMITL2ARFL  \n",
      "3   None  EMITL2ARFL  \n",
      "4   None  EMITL2ARFL  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "       meta.concept-id                                meta.native-id  \\\n",
      "0  G2677797595-LPCLOUD  EMIT_L2A_RFL_001_20230429T113204_2311907_026   \n",
      "1  G2794186271-LPCLOUD  EMIT_L2A_RFL_001_20231029T110354_2330207_024   \n",
      "2  G2827183842-LPCLOUD  EMIT_L2A_RFL_001_20231229T105501_2336307_006   \n",
      "3  G3142899424-LPCLOUD  EMIT_L2A_RFL_001_20240628T105037_2418007_007   \n",
      "4  G3149675777-LPCLOUD  EMIT_L2A_RFL_001_20240702T091532_2418406_008   \n",
      "\n",
      "  umm.TemporalExtent.RangeDateTime.BeginningDateTime  \\\n",
      "0                               2023-04-29T11:32:04Z   \n",
      "1                               2023-10-29T11:03:54Z   \n",
      "2                               2023-12-29T10:55:01Z   \n",
      "3                               2024-06-28T10:50:37Z   \n",
      "4                               2024-07-02T09:15:32Z   \n",
      "\n",
      "  umm.TemporalExtent.RangeDateTime.EndingDateTime  umm.CloudCover  \\\n",
      "0                            2023-04-29T11:32:24Z              16   \n",
      "1                            2023-10-29T11:04:14Z              65   \n",
      "2                            2023-12-29T10:55:13Z              80   \n",
      "3                            2024-06-28T10:50:49Z              82   \n",
      "4                            2024-07-02T09:15:44Z              95   \n",
      "\n",
      "  umm.DataGranule.DayNightFlag geometry browse   shortname  \n",
      "0                          Day     None   None  EMITL2ARFL  \n",
      "1                          Day     None   None  EMITL2ARFL  \n",
      "2                          Day     None   None  EMITL2ARFL  \n",
      "3                          Day     None   None  EMITL2ARFL  \n",
      "4                          Day     None   None  EMITL2ARFL  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error creating Shapely object: 'GPolygon'\n",
      "Error creating Shapely object: 'GPolygon'\n",
      "Error creating Shapely object: 'GPolygon'\n",
      "Error creating Shapely object: 'GPolygon'\n",
      "Error creating Shapely object: 'GPolygon'\n",
      "Error creating Shapely object: 'GPolygon'\n",
      "Error creating Shapely object: 'GPolygon'\n",
      "Error creating Shapely object: 'GPolygon'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import sys  # Import sys for error printing\n",
    "import earthaccess  # Import earthaccess\n",
    "\n",
    "\n",
    "def convert_bounds(bounds):\n",
    "    \"\"\"Convert Shapely bounds to Folium bounds (swapped).\"\"\"\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    return [(miny, minx), (maxy, maxx)]\n",
    "\n",
    "\n",
    "def ensure_counterclockwise(polygon):\n",
    "    \"\"\"\n",
    "    Ensures that the given Shapely Polygon's exterior ring is oriented counter-clockwise.\n",
    "\n",
    "    Args:\n",
    "        polygon: A Shapely Polygon object.\n",
    "\n",
    "    Returns:\n",
    "        A Shapely Polygon object with a counter-clockwise oriented exterior ring.\n",
    "    \"\"\"\n",
    "    if not polygon.exterior.is_ccw:\n",
    "        coords = list(polygon.exterior.coords)\n",
    "        return Polygon(coords[::-1], holes=[list(interior.coords) for interior in polygon.interiors])\n",
    "    return polygon\n",
    "\n",
    "def polygon_to_coord_list(polygon):\n",
    "    \"\"\"\n",
    "    Converts a Shapely Polygon to a list of coordinate tuples.\n",
    "\n",
    "    Args:\n",
    "        polygon: A Shapely Polygon object\n",
    "\n",
    "    Returns:\n",
    "        A list of coordinate tuples representing the exterior ring of the polygon.\n",
    "        e.g., [(x1, y1), (x2, y2), ..., (xn, yn)]\n",
    "    \"\"\"\n",
    "    return list(polygon.exterior.coords)\n",
    "\n",
    "\n",
    "\n",
    "def get_shapely_object(granule):\n",
    "    \"\"\"\n",
    "    Extracts the bounding geometry from a granule dictionary and returns a Shapely Polygon.\n",
    "\n",
    "    Args:\n",
    "        granule (dict): A granule dictionary from the Earthdata search results.\n",
    "\n",
    "    Returns:\n",
    "        shapely.Polygon: A Shapely Polygon representing the granule's bounding box, or None on error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        coordinates = granule[\"umm\"][\"SpatialExtent\"][\"HorizontalSpatialDomain\"][\"Geometry\"][\"GPolygon\"][\"Boundary\"][\"Point\"]\n",
    "        #  Extract the coordinates into a list of tuples\n",
    "        coords = [(p[\"Longitude\"], p[\"Latitude\"]) for p in coordinates]\n",
    "        return Polygon(coords)\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating Shapely object: {e}\", file=sys.stderr)\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def get_png(granule):\n",
    "    \"\"\"\n",
    "    Extracts the browse URL from a granule dictionary.\n",
    "\n",
    "    Args:\n",
    "        granule (dict): A granule dictionary from the Earthdata search results.\n",
    "\n",
    "    Returns:\n",
    "        str: The URL of the PNG browse image, or None if not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for url in granule[\"RelatedUrls\"]:\n",
    "            if url[\"Type\"] == \"BROWSE\":\n",
    "                return url[\"URL\"]\n",
    "        return None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to orchestrate the data search, processing, and display.\"\"\"\n",
    "    # Example Ecoregion polygon (replace with your actual polygon)\n",
    "    site_roi_coords = [(0.0, 0.0), (3.0, 0.0), (3.0, 3.0), (0.0, 3.0), (0.0, 0.0)]\n",
    "    site_roi_polygon = Polygon(site_roi_coords)\n",
    "    site_roi_polygon = ensure_counterclockwise(site_roi_polygon)\n",
    "    site_roi_coords_list = polygon_to_coord_list(site_roi_polygon) # Get coords list\n",
    "\n",
    "    emit_concept_id = \"C2408750690-LPCLOUD\"\n",
    "    date_range = (\"2022-01-01T00:00:00Z\", \"2024-11-01T23:59:59Z\")\n",
    "    emit_query_results = [] # Initialize here\n",
    "    emit_gdf = None # Initialize emit_gdf\n",
    "\n",
    "    try:\n",
    "        emit_query_results = earthaccess.search_data(\n",
    "            concept_id=emit_concept_id,\n",
    "            polygon=site_roi_coords_list,  # Pass the list of coordinates\n",
    "            temporal=date_range,\n",
    "            count=500,\n",
    "        )\n",
    "        print(f\"Found {len(emit_query_results)} results.\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during data search: {e}\", file=sys.stderr)\n",
    "        return  # Exit if the search fails\n",
    "\n",
    "\n",
    "    # Create Dataframe of Results Metadata\n",
    "    emit_results_df = pd.json_normalize(emit_query_results)\n",
    "    if (emit_results_df.empty):\n",
    "        print(\"No results found, exiting\")\n",
    "        return\n",
    "\n",
    "    # Create shapely polygons for result\n",
    "    geometries = [get_shapely_object(granule) for granule in emit_query_results]\n",
    "    # Convert to GeoDataframe\n",
    "    emit_gdf = gpd.GeoDataFrame(emit_results_df, geometry=geometries, crs=\"EPSG:4326\")\n",
    "    # Remove emit_results_df, no longer needed\n",
    "    del emit_results_df\n",
    "    # Add browse imagery links\n",
    "    emit_gdf['browse'] = [get_png(granule) for granule in emit_query_results]\n",
    "    emit_gdf['shortname'] = [result['umm']['CollectionReference']['ShortName'] for result in emit_query_results]\n",
    "    # Preview GeoDataframe\n",
    "    print(f'{emit_gdf.shape[0]} granules total')\n",
    "    print(emit_gdf.head())\n",
    "\n",
    "    # Create a list of columns to keep\n",
    "    keep_cols = ['meta.concept-id','meta.native-id', 'umm.TemporalExtent.RangeDateTime.BeginningDateTime','umm.TemporalExtent.RangeDateTime.EndingDateTime','umm.CloudCover','umm.DataGranule.DayNightFlag','geometry','browse', 'shortname']\n",
    "    # Remove unneeded columns\n",
    "    emit_gdf = emit_gdf[emit_gdf.columns.intersection(keep_cols)]\n",
    "    print(emit_gdf.head())\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emit_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m keep_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta.concept-id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta.native-id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.TemporalExtent.RangeDateTime.BeginningDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.TemporalExtent.RangeDateTime.EndingDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.CloudCover\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.DataGranule.DayNightFlag\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrowse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Remove unneeded columns\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m emit_gdf \u001b[38;5;241m=\u001b[39m \u001b[43memit_gdf\u001b[49m[emit_gdf\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mintersection(keep_cols)]\n\u001b[0;32m      5\u001b[0m emit_gdf\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emit_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a list of columns to keep\n",
    "keep_cols = ['meta.concept-id','meta.native-id', 'umm.TemporalExtent.RangeDateTime.BeginningDateTime','umm.TemporalExtent.RangeDateTime.EndingDateTime','umm.CloudCover','umm.DataGranule.DayNightFlag','geometry','browse', 'shortname']\n",
    "# Remove unneeded columns\n",
    "emit_gdf = emit_gdf[emit_gdf.columns.intersection(keep_cols)]\n",
    "emit_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking better, but we can make it more readable by renaming our columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emit_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Rename some Columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43memit_gdf\u001b[49m\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta.concept-id\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcept_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta.native-id\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgranule\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.TemporalExtent.RangeDateTime.BeginningDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.TemporalExtent.RangeDateTime.EndingDateTime\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mend_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      5\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.CloudCover\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcloud_cover\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mumm.DataGranule.DayNightFlag\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday_night\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m emit_gdf\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emit_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "# Rename some Columns\n",
    "emit_gdf.rename(columns = {'meta.concept-id':'concept_id','meta.native-id':'granule',\n",
    "                           'umm.TemporalExtent.RangeDateTime.BeginningDateTime':'start_datetime',\n",
    "                           'umm.TemporalExtent.RangeDateTime.EndingDateTime':'end_datetime',\n",
    "                           'umm.CloudCover':'cloud_cover',\n",
    "                           'umm.DataGranule.DayNightFlag':'day_night'}, inplace=True)\n",
    "emit_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note: If querying on-premises (not cloud) LP DAAC datasets, the `meta.concept-id` will not show as `xxxxxx-LPCLOUD`. For these datasets, the granule name can be retrieved from the `umm.DataGranule.Identifiers` column.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can filter using the day/night flag as well, since we need a daytime collection to be comparable to the NEON data (which is captured at a high solar angle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# emit_gdf = emit_gdf[emit_gdf['day_night'].str.contains('Day')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step toward filtering the datasets will be to add a column with a `datetime`. \n",
    "\n",
    "> **You may have noticed that the date format is similar for ECOSTRESS and EMIT, but the ECOSTRESS data also includes fractional seconds. If working locally using `lpdaac_vitals` python environment, you may need to pass the `format='ISO8601'`argument to the `to_datetime` function, as shown in the commented-out line due to a difference in versions of pandas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emit_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#emit_gdf['datetime_obj'] = pd.to_datetime(emit_gdf['start_datetime']) # 2i2c\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m emit_gdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_obj\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43memit_gdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstart_datetime\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mISO8601\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Local ENV\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emit_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "#emit_gdf['datetime_obj'] = pd.to_datetime(emit_gdf['start_datetime']) # 2i2c\n",
    "emit_gdf['datetime_obj'] = pd.to_datetime(emit_gdf['start_datetime'], format='ISO8601') # Local ENV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can roughly visualize the quantity of results by month at our location using a histogram with 10 bins (2022 - 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'emit_gdf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43memit_gdf\u001b[49m\u001b[38;5;241m.\u001b[39mhist(column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_obj\u001b[39m\u001b[38;5;124m'\u001b[39m, by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortname\u001b[39m\u001b[38;5;124m'\u001b[39m, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, sharey\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m);\n",
      "\u001b[1;31mNameError\u001b[0m: name 'emit_gdf' is not defined"
     ]
    }
   ],
   "source": [
    "emit_gdf.hist(column='datetime_obj', by='shortname', bins=10, color='green', edgecolor='black', linewidth=1, sharey=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Visualizing Intersecting Coverage\n",
    "\n",
    "Now that we have geodataframes containing some co-located data, we can visualize them on a map using `folium`. It's often difficult to visualize a large time-series of scenes, so we've included an example in Appendix A1 on how to filter to a single day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'explore'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m folium\u001b[38;5;241m.\u001b[39mGeoJson(site_bbox,\n\u001b[0;32m      9\u001b[0m                 name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbounding_box\u001b[39m\u001b[38;5;124m'\u001b[39m,)\u001b[38;5;241m.\u001b[39madd_to(map1)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Add roi geodataframe\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43msite_polygon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplore\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflightbxID\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m                       popup\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     14\u001b[0m                       categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m                       cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m                       style_kwds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(opacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, fillOpacity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.4\u001b[39m),\n\u001b[0;32m     17\u001b[0m                       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSOAP ROI\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m                       m\u001b[38;5;241m=\u001b[39mmap1)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Plot STAC EMITL2ARFL Results - note we must drop the datetime_obj columns for this to work\u001b[39;00m\n\u001b[0;32m     21\u001b[0m emit_gdf_clear\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime_obj\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mexplore(\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgranule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'explore'"
     ]
    }
   ],
   "source": [
    "# Plot Using Folium\n",
    "# Create Figure and Select Background Tiles\n",
    "fig = Figure(width=\"750px\", height=\"375px\")\n",
    "map1 = folium.Map(tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}', attr='Google')\n",
    "fig.add_child(map1)\n",
    "\n",
    "# Add Site Bounding Box\n",
    "folium.GeoJson(site_bbox,\n",
    "                name='bounding_box',).add_to(map1)\n",
    "\n",
    "# Add roi geodataframe\n",
    "site_polygon.explore(\"flightbxID\",\n",
    "                      popup=True,\n",
    "                      categorical=True,\n",
    "                      cmap='Set3',\n",
    "                      style_kwds=dict(opacity=0.7, fillOpacity=0.4),\n",
    "                      name=\"SOAP ROI\",\n",
    "                      m=map1)\n",
    "\n",
    "# Plot STAC EMITL2ARFL Results - note we must drop the datetime_obj columns for this to work\n",
    "emit_gdf_clear.drop(columns=['datetime_obj']).explore(\n",
    "    \"granule\",\n",
    "    categorical=True,\n",
    "    tooltip=[\n",
    "        \"granule\",\n",
    "        \"start_datetime\",\n",
    "        \"cloud_cover\",\n",
    "    ],\n",
    "    popup=True,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"EMIT\",\n",
    "    m=map1,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "map1.fit_bounds(bounds=convert_bounds(emit_gdf.unary_union.bounds))\n",
    "map1.add_child(folium.LayerControl())\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Previewing EMIT Browse Imagery\n",
    "The EMIT browse imagery is not orthorectified, so to get an idea what scenes look like, we can plot them in a grid using matplotlib.\n",
    "\n",
    "> Note: The black space is indicative of onboard cloud masking that occurs before data is downlinked from the ISS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = 3\n",
    "rows = math.ceil(len(emit_gdf)/cols)\n",
    "fig, ax = plt.subplots(rows, cols, figsize=(20,20))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for _n, index in enumerate(emit_gdf.index.to_list()):\n",
    "    img = io.imread(emit_gdf['browse'][index])\n",
    "    ax[_n].imshow(img)\n",
    "    ax[_n].set_title(f\"Index: {index} - {emit_gdf['granule'][index]}\")\n",
    "    ax[_n].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Further Filtering\n",
    "\n",
    "We can see that some of these granules likely won't work because of the large amount of cloud cover, we can use a list of these to filter them out. Make a list of indexes to filter out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a threshold for cloud cover and filter to remove scenes with >50% cloud cover\n",
    "emit_gdf_clear = emit_gdf[emit_gdf.cloud_cover < 30]\n",
    "emit_gdf_clear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out the bad granules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are some scenes with low (<30%) cloud cover. \n",
    "\n",
    "Let's take a look at the July 27, 2024 EMIT dataset (Index 15):\n",
    "\n",
    "- **20**: `EMIT_L2A_RFL_001_20240727T212942_2420914_005`\n",
    "\n",
    "We can plot this scene as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,8))\n",
    "img = io.imread(emit_gdf['browse'][20])\n",
    "ax.imshow(img)\n",
    "ax.set_title(f\"{emit_gdf['granule'][20]}\")\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can now go back to our `folium` plot above and  re-run the cell to update it based on our filtering.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emit_gdf_july_2023 = emit_gdf[emit_gdf['granule'] == 'EMIT_L2A_RFL_001_20230731T205320_2321214_004']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Using Folium\n",
    "# Create Figure and Select Background Tiles\n",
    "fig = Figure(width=\"750px\", height=\"375px\")\n",
    "map1 = folium.Map(tiles='https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}', attr='Google')\n",
    "fig.add_child(map1)\n",
    "\n",
    "# Add the Site Bounding Box\n",
    "folium.GeoJson(site_bbox,\n",
    "                name='bounding_box',\n",
    "                ).add_to(map1)\n",
    "\n",
    "# Add roi geodataframe\n",
    "site_polygon.explore(\"flightbxID\",\n",
    "                      popup=True,\n",
    "                      categorical=True,\n",
    "                      cmap='Set3',\n",
    "                      style_kwds=dict(opacity=0.7, fillOpacity=0.4),\n",
    "                      name=\"SOAP ROI\",\n",
    "                      m=map1)\n",
    "\n",
    "# Plot STAC EMITL2ARFL Results - note we must drop the datetime_obj columns for this to work\n",
    "emit_gdf_july_2023.drop(columns=['datetime_obj']).explore(\n",
    "    \"granule\",\n",
    "    categorical=True,\n",
    "    tooltip=[\n",
    "        \"granule\",\n",
    "        \"start_datetime\",\n",
    "        \"cloud_cover\",\n",
    "    ],\n",
    "    popup=True,\n",
    "    style_kwds=dict(fillOpacity=0.1, width=2),\n",
    "    name=\"EMIT\",\n",
    "    m=map1,\n",
    "    legend=False\n",
    ")\n",
    "\n",
    "map1.fit_bounds(bounds=convert_bounds(emit_gdf.unary_union.bounds))\n",
    "map1.add_child(folium.LayerControl())\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generating a list of URLs and downloading data\n",
    "\n",
    "Creating a list of results URLs will include all of these assets, so if we only want a subset we need an additional filter to keep the specific assets we want.\n",
    "\n",
    "If you look back, you can see we kept the same indexing throughout the notebook. This enables us to simply subset the `earthaccess` results object to retrieve the results we want. \n",
    "\n",
    "Create a list of index values to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keep_granules = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the results list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_results = [result for i, result in enumerate(emit_query_results) if i in keep_granules]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download all of the associated assets, or retrieve the URLS and further filter them to specifically what we want. \n",
    "\n",
    "First, log into Earthdata using the `login` function from the `earthaccess` library. The `persist=True` argument will create a local `.netrc` file if it doesn't exist, or add your login info to an existing `.netrc` file. If no Earthdata Login credentials are found in the `.netrc` you'll be prompted for them. As mentioned in section 1.2, this step is not necessary to conduct searches, but is needed to download or stream data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can download all assets using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download All Assets for Granules in Filtered Results\n",
    "earthaccess.download(filtered_results, '../data/SOAP/emit_refl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can create a list of URLs and use that to further refine which files we download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve URLS for Assets\n",
    "results_urls = [granule.data_links() for granule in filtered_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see this is a nested list. Granules often have several assets associated with them, for example, `EMIT_L2A` has several assets:\n",
    "\n",
    "- RFL\n",
    "- RFLUNCERT\n",
    "- MASK\n",
    "  \n",
    "The results list we just generated contains URLs to all of these assets nested by granule. We can further filter our results list using string matching to remove unwanted assets.\n",
    "\n",
    "Create a list of strings and enumerate through our results_url list to filter out unwanted assets and remove the nesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_asset_links = []\n",
    "# Pick Desired Assets (leave _ on RFL to distinguish from RFLUNC, LST. to distinguish from LST_err)\n",
    "desired_assets = ['RFL_','MASK', 'LST.'] # Add more or do individually for reflectance, reflectance uncertainty, or mask\n",
    "# Step through each sublist (granule) and filter based on desired assets.\n",
    "for n, granule in enumerate(results_urls):\n",
    "    for url in granule: \n",
    "        asset_name = url.split('/')[-1]\n",
    "        if any(asset in asset_name for asset in desired_assets):\n",
    "            filtered_asset_links.append(url)\n",
    "filtered_asset_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this removed the `REFLUNCERT` data. We can also write this list of files to a text file to have a record of data used, or stream the data using `https` as we access them. For streaming the data, the EMIT files are very large, so operations can take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./data/emit_search_results.txt', 'w') as f:\n",
    "    for line in filtered_asset_links:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the list of required granules.\n",
    "\n",
    ">Note: You can download all of the files using the cell below and recreate all of the canopy water content files following a workflow similar to the example in notebooks 2 and 3 for all of the necessary scenes. To do this, uncomment the `file_list` object with the `emit_search_results.txt` filepath to download all of the results rather than just what is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Open Text File and Read Lines\n",
    "#file_list = './data/required_granules.txt'\n",
    "file_list = './data/emit_search_results.txt'\n",
    "with open(file_list) as f:\n",
    "    urls = [line.rstrip('\\n') for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the required granules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a directory to store the downloaded emit data\n",
    "os.makedirs('./data/emit_refl', exist_ok=True)\n",
    "# Get requests https session using Earthdata Login Info\n",
    "fs = earthaccess.get_requests_https_session()\n",
    "# Retrieve granule asset ID from URL (to maintain existing naming convention)\n",
    "for url in urls:\n",
    "    granule_asset_id = url.split('/')[-1]\n",
    "    # Define Local Filepath\n",
    "    fp = f'./data/emit_refl/{granule_asset_id}'\n",
    "    # Download the Granule Asset if it doesn't exist\n",
    "    if not os.path.isfile(fp):\n",
    "        with fs.get(url,stream=True) as src:\n",
    "            with open(fp,'wb') as dst:\n",
    "                for chunk in src.iter_content(chunk_size=64*1024*1024):\n",
    "                    dst.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, now you have downloaded co-located hyperspectral reflectance data from NEON airborne collections and the EMIT instrument on the ISS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contact Info:  \n",
    "\n",
    "**Land Processes Distributed Active Archive Center (LP DAAC)**<sup>1</sup>\n",
    "\n",
    "Email: LPDAAC@usgs.gov  \n",
    "Voice: +1-866-573-3222  \n",
    "Website: <https://lpdaac.usgs.gov/>  \n",
    "\n",
    "<sup>1</sup>Work performed under USGS contract G15PD00467 for NASA contract NNG14HH33I. \n",
    "\n",
    "**National Ecological Observatory Network (NEON)**<sup>2</sup>\n",
    "\n",
    "Website: <https://www.neonscience.org/>   \n",
    "Contact: <https://www.neonscience.org/about/contact-us>   \n",
    "Date last modified: 08-27-2024 \n",
    "\n",
    "<sup>2</sup>NEON is a project sponsored by the National Science Foundation and operated by Battelle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
